{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43edb882",
   "metadata": {},
   "source": [
    "# 1 - dataset_loaders.yaml\n",
    "\n",
    "* This configuration file stores the settings of all datasets that will be utilized during the execution of an experiment, as can be seen in the example below for the **MovieLens 100k** dataset.\n",
    "\n",
    "<!-- Which one is better? -->\n",
    "<!-- * This configuration file stores the settings of all datasets required to run your experiment. Below, there is an example setting for the MovieLens 1M dataset. -->\n",
    "\n",
    "* Example:\n",
    "```yaml\n",
    "'MovieLens 100k': # Dataset name\n",
    "    FullData: # Loader method\n",
    "        dataset: # Info dataset\n",
    "          path: ./data/datasets/MovieLens 100k/ratings.csv\n",
    "          random_seed: 0\n",
    "          file_delimiter: \",\"\n",
    "          skip_head: true\n",
    "\n",
    "        prefiltering: # Filters\n",
    "          filter_users: # By Users\n",
    "            min_consumption: 50\n",
    "            num_users: 100\n",
    "          filter_items: # By Items\n",
    "            min_ratings: 1\n",
    "            num_items: 100\n",
    "\n",
    "        splitting: # Splitting\n",
    "          strategy: temporal\n",
    "          train_size: 0.8\n",
    "          test_consumes: 5\n",
    "\n",
    "        validation:\n",
    "          validation_size: 0.2\n",
    " ```\n",
    " \n",
    " *  If the researcher wants to avoid the prefiltering step, just remove all keys related to the prefiltering steps.\n",
    " *  The standard data template for ratings consists of 4 comma-separated columns.\n",
    "     user_id,item_id,rating,timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eccd718",
   "metadata": {},
   "source": [
    "# 2 - agents.yaml\n",
    "\n",
    "* As its name suggests, this configuration file stores the settings of all agents utilized in the experiments.\n",
    "\n",
    "* Example\n",
    "\n",
    "```yaml\n",
    "LinearEGreedy: # Recommender agent name\n",
    "  SimpleAgent: # Agent type\n",
    "    action_selection_policy: \n",
    "      ASPEGreedy: # Action selection policy\n",
    "        # variables\n",
    "        epsilon: 0.1 \n",
    "    value_function:\n",
    "      LinearEGreedy: # Agent's value function\n",
    "        # variables\n",
    "        item_var: 0.01\n",
    "        iterations: 20\n",
    "        num_lat: 10\n",
    "        stop_criteria: 0.0009\n",
    "        user_var: 0.01\n",
    "        var: 0.05\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973b5fb3",
   "metadata": {},
   "source": [
    "# 3 - dataset_agents.yaml\n",
    "\n",
    "* This configuration file stores the agents and their parameters for each dataset. Usually, the agent's parameters vary according to the dataset, therefore it is convenient to store the best values found for each one. The results of a grid search on an agent will tell us which were the best parameters found for them, these data can then be stored in this file in case you want to reproduce the experiment later on.\n",
    "\n",
    "* We can see in the example below the best parameters found for agents **LinUCB** and **LinearEGreedy** in the **MovieLens 100k** dataset.\n",
    "\n",
    "```yaml\n",
    "'MovieLens 100k':\n",
    "\n",
    "  LinUCB:\n",
    "    SimpleAgent:\n",
    "      action_selection_policy:\n",
    "        ASPGreedy: {}\n",
    "      value_function:\n",
    "        LinUCB:\n",
    "          alpha: 1.0\n",
    "          num_lat: 10\n",
    "\n",
    "  LinearEGreedy:\n",
    "    SimpleAgent:\n",
    "      action_selection_policy:\n",
    "        ASPEGreedy:\n",
    "          epsilon: 0.1\n",
    "      value_function:\n",
    "        LinearEGreedy:\n",
    "          item_var: 0.01\n",
    "          iterations: 20\n",
    "          num_lat: 10\n",
    "          stop_criteria: 0.0009\n",
    "          user_var: 0.01\n",
    "          var: 0.05\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4926ae6",
   "metadata": {},
   "source": [
    "# 4 - evaluation_policies.yaml\n",
    "\n",
    "* The evaluation policies are defined in this configuration file. To conduct an experiment, we need to define how the recommendation process will be executed and the user-item interactions. We specify these settings in this file according to the experiment's objectives.\n",
    "\n",
    "* In the example below we can observe one of the evaluation policies implemented in the framework: **Interaction**, with its respective parameters.\n",
    "\n",
    "```yaml\n",
    "FixedInteraction: # Evaluation Policy\n",
    "  num_interactions: 100 # Num of interactions for each user\n",
    "  interaction_size: 1 # Num of itens that will be recommended for each interaction\n",
    "  save_info: False # Wheter or not to save the information obtained during the evaluation.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46ec8c9",
   "metadata": {},
   "source": [
    "# 5 - metric_evaluators.yaml\n",
    "\n",
    "* In this file, it is defined evaluation metrics for an experiment. It specifies how to assess the interactions performed during the evaluation process..\n",
    "\n",
    "* In the example below we can see the use of an evaluation metric named **UserCumulativeInteraction** with its recpective parameters.\n",
    "\n",
    "```yaml\n",
    "UserCumulativeInteraction:\n",
    "  interaction_size: 1 # Num of itens that will be recommended for each interaction\n",
    "  interactions_to_evaluate: # Interactions that will be evaluated\n",
    "    - 5\n",
    "    - 10\n",
    "    - 20\n",
    "    - 50\n",
    "    - 100\n",
    "  num_interactions: 100 # Num of interactions for each user\n",
    "  relevance_evaluator_threshold: 3.999 # Rating\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127bd779",
   "metadata": {},
   "source": [
    "# 6 - agents_variables.yaml\n",
    "\n",
    "* In the irec-cmdline, it can be done by defining these information in the file agents_variables.yaml as illustrated in the configuration below. The first name should refer to the tuning ap- proach selected (e.g., the Grid Search). Then, the remaining setting file is quite similar to the one that represents the agent templates illustrated previously. However, instead of passing only one parameter, the researcher must set a list of parameters to be explored. This example presents the configuration for the classical bandit algorithms of ùúñ-Greedy (ùúñ ‚àà [0.1, 1]), UCB (ùëê ‚àà [0.1, 1]) and Thompson Sampling (ùëéùëôùëù‚Ñéùëé ‚àà [0.1, 1]; ùëèùëíùë°ùëé ‚àà [1, 100] ).\n",
    "\n",
    "\n",
    "```yaml\n",
    "GridSearch:\n",
    "\n",
    "  - EGreedy:\n",
    "      SimpleAgent:\n",
    "        action_selection_policy:\n",
    "          ASPEGreedy:\n",
    "            epsilon: linspace(0.1, 1, 5)\n",
    "        value_function:\n",
    "          EGreedy: {}\n",
    "  - UCB:\n",
    "      SimpleAgent:\n",
    "        action_selection_policy:\n",
    "          ASPGreedy: {}\n",
    "        value_function:\n",
    "          UCB:\n",
    "            c: linspace(0.1, 1, 5)\n",
    "    \n",
    "  - ThompsonSampling:\n",
    "      SimpleAgent:\n",
    "        action_selection_policy:\n",
    "          ASPGreedy: {}\n",
    "        value_function:\n",
    "          ThompsonSampling:\n",
    "            alpha_0: linspace(0.1, 1, 5)\n",
    "            beta_0: linspace(1, 100, 10)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0af15e7",
   "metadata": {},
   "source": [
    "# 7 - defaults.yaml\n",
    "\n",
    "* This configuration file defines the general settings of an experiment. We can specify not only the agents, the base, the policy, and the evaluation metric, but also some additional information.\n",
    "\n",
    "* Example\n",
    "```yaml\n",
    "agent: UCB\n",
    "agent_experiment: agent\n",
    "data_dir: data/\n",
    "dataset_experiment: dataset\n",
    "dataset_loader: 'MovieLens 100k'\n",
    "evaluation_experiment: evaluation\n",
    "evaluation_policy: FixedInteraction\n",
    "metric: Hits\n",
    "metric_evaluator: UserCumulativeInteraction\n",
    "pdf_dir: pdf/\n",
    "tex_dir: tex/\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
